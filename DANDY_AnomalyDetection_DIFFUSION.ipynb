{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1IDOvlY7B54uxIuf-xHDkncYFFluKyvzL","authorship_tag":"ABX9TyO7cn0KdFug4C2oTxoENt1e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["##### ANOMALY DETECTION WITH DIFFUSION - RESIDUAL / SPECTRAL #####\n","#\n","### Algorithm 1: Training (Diffusion-Based Denoising Model)\n","# Load StepChange training signal for a given residence and appliance\n","# Sample a diffusion timestep and inject Gaussian noise into each window\n","# Train a UNet1D model to predict the injected noise\n","# Optimize mean-squared error between true and predicted noise\n","# Repeat for all epochs and save trained model\n","#\n","### Algorithm 2: Inference (Residual-Spectral Anomaly Detection)\n","# Reconstruct windows using the trained diffusion model\n","# Compute time-domain and frequency-domain reconstruction errors\n","# Normalize errors using robust z-scoring and combine into an anomaly score\n","# Classify samples as anomalous using a percentile threshold\n","#\n","#"],"metadata":{"id":"BM3RV4kpUwxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# IMPORTS\n","# ============================================================\n","import os\n","import time\n","import psutil\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from scipy.fft import fft\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    confusion_matrix\n",")\n","\n","# ============================================================\n","# LOGGER\n","# ============================================================\n","def log(msg):\n","    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\", flush=True)\n","\n","# ============================================================\n","# CONFIGURATION\n","# ============================================================\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","WINDOW_SIZE = 24\n","BATCH_SIZE = 64\n","EPOCHS = 30\n","LR = 1e-4\n","\n","BASE = \"/content/drive/MyDrive/Paper02_14Datasets\"\n","MERGED_DIR = f\"{BASE}/MERGED\"\n","OUT_DIR = f\"{BASE}/ANOMALY_DIFFUSION_RESIDUALSPECTRAL\"\n","SUMMARY_DIR = f\"{OUT_DIR}/Percentiles_Summary\"\n","\n","os.makedirs(OUT_DIR, exist_ok=True)\n","os.makedirs(SUMMARY_DIR, exist_ok=True)\n","\n","# ============================================================\n","# RESIDENCES / APPLIANCES / ANOMALIES\n","# ============================================================\n","RESIDENCES = [\n","    \"AMPds2_House01\",\n","    \"GREEND_House00\", \"GREEND_House01\", \"GREEND_House03\",\n","    \"UKDALE_House01\", \"UKDALE_House02\", \"UKDALE_House05\",\n","    \"REFIT_House01\", \"REFIT_House02\", \"REFIT_House03\", \"REFIT_House05\",\n","    \"REFIT_House07\", \"REFIT_House09\", \"REFIT_House15\",\n","]\n","\n","APPLIANCES = [\n","    \"Fridge\",\n","    \"WashingMachine\",\n","    \"Dishwasher\",\n","]\n","\n","ANOMALIES = [\n","    \"StepChange\",\n","    \"MultiStepChange\",\n","    \"Repeating\",\n","    \"Mirror\",\n","    \"StuckMAX\",\n","    \"StuckMIN\",\n","    \"PowerCycling\",\n","]\n","\n","THRESHOLDS = [95]  # Percentiles to loop through\n","\n","# ============================================================\n","# DATASET AND WINDOWS\n","# ============================================================\n","class PowerDataset(Dataset):\n","    def __init__(self, series):\n","        self.series = series\n","\n","    def __len__(self):\n","        return len(self.series)\n","\n","    def __getitem__(self, idx):\n","        # Each item is a 1D window -> shape (1, WINDOW_SIZE)\n","        return torch.tensor(self.series[idx], dtype=torch.float32).unsqueeze(0)\n","\n","def create_windows(signal, window=WINDOW_SIZE):\n","    \"\"\"\n","    Creates non-overlapping windows of length `window`.\n","    If the signal length is not divisible by `window`,\n","    the leftover tail is ignored (handled later by padding scores).\n","    \"\"\"\n","    return np.array([\n","        signal[i:i + window]\n","        for i in range(0, len(signal) - window + 1, window)\n","    ])\n","\n","# ============================================================\n","# SIMPLE UNET1D\n","# ============================================================\n","class UNet1D(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.enc = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n","        self.dec = nn.Conv1d(16, 1, kernel_size=3, padding=1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        e = self.relu(self.enc(x))\n","        d = self.dec(e)\n","        return d + x  # skip connection\n","\n","# ============================================================\n","# DDPM\n","# ============================================================\n","class DDPM:\n","    def __init__(self, T=1000):\n","        self.T = T\n","        self.beta = torch.linspace(1e-4, 0.02, T).to(DEVICE)\n","        self.alpha = 1.0 - self.beta\n","        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n","\n","    def add_noise(self, x0, t):\n","        eps = torch.randn_like(x0)\n","        a_bar = self.alpha_bar[t].view(-1, 1, 1)\n","\n","        # Forward diffusion equation\n","        xt = torch.sqrt(a_bar) * x0 + torch.sqrt(1 - a_bar) * eps\n","        return xt, eps\n","\n","# ============================================================\n","# TRAINING\n","# ============================================================\n","def train_model(train_loader):\n","    log(\"Initializing UNet1D diffusion model\")\n","    model = UNet1D().to(DEVICE)\n","    ddpm = DDPM()\n","    opt = torch.optim.Adam(model.parameters(), lr=LR)\n","    loss_fn = nn.MSELoss()\n","\n","    model.train()\n","    start_time = time.time()\n","\n","    for epoch in range(EPOCHS):\n","        log(f\"Epoch {epoch + 1}/{EPOCHS} started\")\n","        for x in train_loader:\n","            x = x.to(DEVICE)\n","            t = torch.randint(0, ddpm.T, (x.size(0),)).to(DEVICE)\n","\n","            ## EQUATION - Forward Diffusion\n","            xt, eps = ddpm.add_noise(x, t)\n","\n","            eps_hat = model(xt)\n","            loss = loss_fn(eps_hat, eps)\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","\n","        log(f\"Epoch {epoch + 1} completed\")\n","\n","    elapsed = time.time() - start_time\n","    log(f\"Training finished in {elapsed:.2f} seconds\")\n","    return model, elapsed\n","\n","# ============================================================\n","# ANOMALY SCORE\n","# ============================================================\n","def compute_scores(x, x_hat):\n","    # Time-domain reconstruction error (per window)\n","    mae_t = np.mean(np.abs(x - x_hat), axis=1)\n","\n","    # Frequency-domain reconstruction error (per window)\n","    rx = np.log1p(np.abs(fft(x)))\n","    rx_hat = np.log1p(np.abs(fft(x_hat)))\n","    mae_f = np.mean(np.abs(rx - rx_hat), axis=1)\n","\n","    # Robust z-score using MAD\n","    def z_robust(v):\n","        med = np.median(v)\n","        mad = np.median(np.abs(v - med)) + 1e-6\n","        return (v - med) / mad\n","\n","    ## EQUATION - Score Calculation based on mae_t and mae_f\n","    score = 0.5 * (z_robust(mae_t) + z_robust(mae_f))\n","    return score\n","\n","# ============================================================\n","# MAIN PIPELINE\n","# ============================================================\n","log(\"Starting diffusion anomaly detection pipeline\")\n","\n","for res in RESIDENCES:\n","    stats = []\n","\n","    for appliance in APPLIANCES:\n","\n","        # ------------------ TRAINING (always StepChange) ---------------------\n","        train_path = f\"{MERGED_DIR}/{res}_{appliance}_15minutes_StepChange_MERGED.csv\"\n","        if not os.path.exists(train_path):\n","            log(f\"⚠️ Missing training file, skipping: {train_path}\")\n","            continue\n","\n","        log(f\"Loading training data: {train_path}\")\n","        df_train = pd.read_csv(train_path)\n","\n","        if \"active_power\" not in df_train.columns:\n","            log(f\"⚠️ Missing 'active_power' column in training file, skipping: {train_path}\")\n","            continue\n","\n","        signal_train = df_train[\"active_power\"].values\n","        windows_train = create_windows(signal_train)\n","\n","        if len(windows_train) == 0:\n","            log(f\"⚠️ No training windows produced, skipping: {train_path}\")\n","            continue\n","\n","        train_ds = PowerDataset(windows_train)\n","        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","\n","        train_peak_mb = psutil.Process().memory_info().rss / (1024 ** 2)\n","        model, train_time = train_model(train_loader)\n","\n","        # Compute training scores (used to set percentile threshold)\n","        model.eval()\n","        with torch.no_grad():\n","            recon_train = model(\n","                torch.tensor(windows_train).float().unsqueeze(1).to(DEVICE)\n","            ).cpu().numpy().squeeze()\n","\n","        scores_train = compute_scores(windows_train, recon_train)\n","\n","        # ------------------ INFERENCE ---------------------\n","        for anomaly in ANOMALIES:\n","            infer_path = f\"{MERGED_DIR}/{res}_{appliance}_15minutes_{anomaly}_MERGED.csv\"\n","            if not os.path.exists(infer_path):\n","                log(f\"⚠️ Missing inference file, skipping: {infer_path}\")\n","                continue\n","\n","            log(f\"Inference for: {res} | {appliance} | {anomaly}\")\n","            df = pd.read_csv(infer_path)\n","\n","            if \"active_power\" not in df.columns or \"ground_truth_anomaly\" not in df.columns:\n","                log(f\"⚠️ Missing required columns in inference file, skipping: {infer_path}\")\n","                continue\n","\n","            windows = create_windows(df[\"active_power\"].values)\n","            if len(windows) == 0:\n","                log(f\"⚠️ No inference windows produced, skipping: {infer_path}\")\n","                continue\n","\n","            start_inf = time.time()\n","            with torch.no_grad():\n","                recon = model(\n","                    torch.tensor(windows).float().unsqueeze(1).to(DEVICE)\n","                ).cpu().numpy().squeeze()\n","\n","            scores = compute_scores(windows, recon)\n","\n","            # ------------------------------------------------------------\n","            # Expand window scores to row scores AND force equal length\n","            # ------------------------------------------------------------\n","            scores_row = np.repeat(scores, WINDOW_SIZE)\n","\n","            if len(scores_row) < len(df):\n","                # pad missing tail rows using last score\n","                scores_row = np.pad(scores_row, (0, len(df) - len(scores_row)), mode=\"edge\")\n","            else:\n","                scores_row = scores_row[:len(df)]\n","\n","            # Normalize ground truth (robust to spacing/case)\n","            gt = df[\"ground_truth_anomaly\"].astype(str).str.strip().str.lower()\n","            y_true = (gt == \"anomaly\").astype(int).to_numpy()\n","\n","            # Actual counts\n","            ActualNormal = int(np.sum(y_true == 0))\n","            ActualAnomaly = int(np.sum(y_true == 1))\n","\n","            # ------------------ LOOP THROUGH THRESHOLDS ---------------------\n","            for pct in THRESHOLDS:\n","                threshold = np.percentile(scores_train, pct)\n","\n","                preds = np.where(scores_row > threshold, \"anomaly\", \"normal\")\n","                y_pred = (preds == \"anomaly\").astype(int)\n","\n","                # ============================================================\n","                # ✅ SAVE PER-INFERENCE FILE WITH PREDICTIONS\n","                # ============================================================\n","                df_out = df.copy()\n","\n","                # Keep pipeline robust (in case some files are missing columns)\n","                if \"timestamp\" not in df_out.columns:\n","                    df_out[\"timestamp\"] = np.arange(len(df_out))\n","                if \"ground_truth_appliance\" not in df_out.columns:\n","                    df_out[\"ground_truth_appliance\"] = \"\"\n","\n","                df_out[\"prediction_anomaly\"] = preds  # \"anomaly\" / \"normal\"\n","\n","                # Keep ONLY requested columns and order\n","                df_out = df_out[[\n","                    \"timestamp\",\n","                    \"active_power\",\n","                    \"ground_truth_anomaly\",\n","                    \"ground_truth_appliance\",\n","                    \"prediction_anomaly\"\n","                ]]\n","\n","                out_pred_csv = (\n","                    f\"{OUT_DIR}/{res}_{appliance}_15minutes_{anomaly}_MERGED_DIFFUSION_RESIDUALSPECTRAL.csv\"\n","                )\n","\n","                df_out.to_csv(out_pred_csv, index=False)\n","                log(f\"✅ Saved predictions file: {out_pred_csv}\")\n","\n","                # confusion_matrix can return 1x1 if only one class exists, so fix labels\n","                cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n","                tn, fp, fn, tp = cm.ravel()\n","\n","                normal_pct = 100.0 * float(np.mean(y_pred == 0))\n","                anomaly_pct = 100.0 * float(np.mean(y_pred == 1))\n","\n","                inf_peak_mb = psutil.Process().memory_info().rss / (1024 ** 2)\n","\n","                stats.append({\n","                    \"Residence\": res,\n","                    \"Appliance\": appliance,\n","                    \"Anomaly\": anomaly,\n","                    \"ThresholdPct\": pct,\n","\n","                    # Requested metrics\n","                    \"Accuracy\": float(accuracy_score(y_true, y_pred)),\n","                    \"Precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n","                    \"Recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n","                    \"F1-Score\": float(f1_score(y_true, y_pred, zero_division=0)),\n","                    \"Normal_pct\": float(normal_pct),\n","                    \"Anomaly_pct\": float(anomaly_pct),\n","                    \"Total\": int(len(y_true)),\n","                    \"TP\": int(tp), \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn),\n","                    \"ActualNormal\": int(ActualNormal),\n","                    \"ActualAnomaly\": int(ActualAnomaly),\n","\n","                    # Extra diagnostics (kept minimal)\n","                    \"TrainTimeSec\": float(train_time),\n","                    \"InferenceTimeSec\": float(time.time() - start_inf),\n","                    \"TrainPeakMB\": float(train_peak_mb),\n","                    \"InferencePeakMB\": float(inf_peak_mb),\n","                })\n","\n","    # ============================================================\n","    # SAVE PER-RESIDENCE OUTLINE CSV\n","    # ============================================================\n","    if len(stats) > 0:\n","        out_csv = f\"{SUMMARY_DIR}/{res}_ANOMALY_DIFFUSION_OUTLINE.csv\"\n","        pd.DataFrame(stats).to_csv(out_csv, index=False)\n","        log(f\"✅ Saved: {out_csv}\")\n","    else:\n","        log(f\"⚠️ No stats collected for {res}; nothing saved.\")\n","\n","log(\"✅ Pipeline completed successfully\")\n"],"metadata":{"id":"Waz1Dutd1q_v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"V9MFDn7e5NyN"}}]}